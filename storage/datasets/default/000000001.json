{
  "url": "https://ai.google.dev/gemini-api/docs/document-processing?lang=python",
  "title": "Explore document processing capabilities with the Gemini API  |  Google AI for Developers",
  "paragraphs": [
    "Python\n  JavaScript\n  Go\n  REST",
    "The Gemini API supports PDF input, including long documents (up to 3600 pages).\nGemini models process PDFs with native vision, and are therefore able to\nunderstand both text and image contents inside documents. With native PDF\nvision support, Gemini models are able to:",
    "This tutorial demonstrates some possible ways to use the Gemini API with PDF\ndocuments. All output is text-only.",
    "Before calling the Gemini API, you need to set up your project and configure\nyour API key.",
    "Expand to view how to set up your project and API key",
    "You need an API key to call the Gemini API. If you don't already have one,\ncreate a key in Google AI Studio.",
    "Get an API key",
    "It's strongly recommended that you do not check an API key into your version\ncontrol system.",
    "You should store your API key in a secrets store such as Google Cloud\nSecret Manager.",
    "This tutorial assumes that you're accessing your API key as an environment\nvariable.",
    "The Python SDK for the Gemini API is contained in the\ngoogle-genai package.",
    "Install the dependency using pip:",
    "Put your API key in the GOOGLE_API_KEY environment\nvariable:",
    "Create an API Client, it will pickup the key from the environment:",
    "This guide demonstrates how to upload and process PDFs\nusing the File API or by including them as inline data.",
    "Gemini 1.5 Pro and 1.5 Flash support a maximum of 3,600 document pages. Document\npages must be in one of the following text data MIME types:",
    "Each document page is equivalent to 258 tokens.",
    "While there are no specific limits to the number of pixels in a document besides\nthe model's context window, larger pages are scaled down to a maximum resolution\nof 3072x3072 while preserving their original aspect ratio, while smaller pages\nare scaled up to 768x768 pixels. There is no cost reduction for pages at lower\nsizes, other than bandwidth, or performance improvement for pages at higher\nresolution.",
    "For best results:",
    "For PDF payloads under 20MB, you can choose between uploading base64\nencoded documents or directly uploading locally stored files.",
    "You can process PDF documents directly from URLs. Here's a code snippet\nshowing how to do this:",
    "For locally stored PDFs, you can use the following approach:",
    "You can use the File API to upload a document of any size. Always use the File\nAPI when the total request size (including the files, text prompt, system\ninstructions, etc.) is larger than 20 MB.",
    "Call media.upload to upload a file using the\nFile API. The following code uploads a document file and then uses the file in a\ncall to\nmodels.generateContent.",
    "Use the File API for large PDF files available from URLs,\nsimplifying the process of uploading and processing these documents directly\nthrough their URLs:",
    "You can verify the API successfully stored the uploaded file and get its\nmetadata by calling files.get. Only the name\n(and by extension, the uri) are unique.",
    "The Gemini API is capable of processing multiple PDF documents in a single\nrequest, as long as the combined size of the documents and the text prompt\nstays within the model's context window.",
    "You can list all files uploaded using the File API and their URIs using\nfiles.list.",
    "Files uploaded using the File API are automatically deleted after 2 days. You\ncan also manually delete them using\nfiles.delete.",
    "It's not possible to retrieve or view cached content, but you can retrieve\ncache metadata (name, model, display_name, usage_metadata,\ncreate_time, update_time, and expire_time).",
    "To list metadata for all uploaded caches, use CachedContent.list():",
    "You can set a new ttl or expire_time for a cache. Changing anything else\nabout the cache isn't supported.",
    "The following example shows how to update the ttl of a cache using\nCachedContent.update().",
    "The caching service provides a delete operation for manually removing content\nfrom the cache. The following example shows how to delete a cache using\nCachedContent.delete().",
    "This guide shows how to use\ngenerateContent and\nto generate text outputs from processed documents. To learn more,\nsee the following resources:",
    "Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.",
    "Last updated 2025-04-01 UTC."
  ],
  "code_blocks": [
    "pip install -U google-genai",
    "export GOOGLE_API_KEY=\"YOUR_KEY_HERE\"",
    "from google import genai\n\nclient = genai.Client()",
    "from google import genai\nfrom google.genai import types\nimport httpx\n\nclient = genai.Client()\n\ndoc_url = \"https://discovery.ucl.ac.uk/id/eprint/10089234/1/343019_3_art_0_py4t4l_convrt.pdf\"  # Replace with the actual URL of your PDF\n\n# Retrieve and encode the PDF byte\ndoc_data = httpx.get(doc_url).content\n\nprompt = \"Summarize this document\"\nresponse = client.models.generate_content(\n  model=\"gemini-1.5-flash\",\n  contents=[\n      types.Part.from_bytes(\n        data=doc_data,\n        mime_type='application/pdf',\n      ),\n      prompt])\nprint(response.text)",
    "from google import genai\nfrom google.genai import types\nimport pathlib\nimport httpx\n\nclient = genai.Client()\n\ndoc_url = \"https://discovery.ucl.ac.uk/id/eprint/10089234/1/343019_3_art_0_py4t4l_convrt.pdf\"  # Replace with the actual URL of your PDF\n\n# Retrieve and encode the PDF byte\nfilepath = pathlib.Path('file.pdf')\nfilepath.write_bytes(httpx.get(doc_url).content)\n\nprompt = \"Summarize this document\"\nresponse = client.models.generate_content(\n  model=\"gemini-1.5-flash\",\n  contents=[\n      types.Part.from_bytes(\n        data=filepath.read_bytes(),\n        mime_type='application/pdf',\n      ),\n      prompt])\nprint(response.text)",
    "from google import genai\nfrom google.genai import types\nimport io\nimport httpx\n\nclient = genai.Client()\n\nlong_context_pdf_path = \"https://www.nasa.gov/wp-content/uploads/static/history/alsj/a17/A17_FlightPlan.pdf\" # Replace with the actual URL of your large PDF\n\n# Retrieve and upload the PDF using the File API\ndoc_io = io.BytesIO(httpx.get(long_context_pdf_path).content)\n\nsample_doc = client.files.upload(\n  # You can pass a path or a file-like object here\n  file=doc_io, \n  config=dict(\n    # It will guess the mime type from the file extension, but if you pass\n    # a file-like object, you need to set the\n    mime_type='application/pdf')\n)\n\nprompt = \"Summarize this document\"\n\n\nresponse = client.models.generate_content(\n  model=\"gemini-1.5-flash\",\n  contents=[sample_doc, prompt])\nprint(response.text)",
    "from google import genai\nfrom google.genai import types\nimport pathlib\nimport httpx\n\nclient = genai.Client()\n\nlong_context_pdf_path = \"https://www.nasa.gov/wp-content/uploads/static/history/alsj/a17/A17_FlightPlan.pdf\" # Replace with the actual URL of your large PDF\n\n# Retrieve the PDF\nfile_path = pathlib.Path('A17.pdf')\nfile_path.write_bytes(httpx.get(long_context_pdf_path).content)\n\n# Upload the PDF using the File API\nsample_file = client.files.upload(\n  file=file_path,\n)\n\nprompt=\"Summarize this document\"\n\nresponse = client.models.generate_content(\n  model=\"gemini-1.5-flash\",\n  contents=[sample_file, \"Summarize this document\"])\nprint(response.text)",
    "from google import genai\nimport pathlib\n\nclient = genai.Client()\n\nfpath = pathlib.Path('example.txt')\nfpath.write_text('hello')\n\nfile = client.files.upload('example.txt')\n\nfile_info = client.files.get(file.name)\nprint(file_info.model_dump_json(indent=4))",
    "from google import genai\nimport io\nimport httpx\n\nclient = genai.Client()\n\ndoc_url_1 = \"https://arxiv.org/pdf/2312.11805\" # Replace with the URL to your first PDF\ndoc_url_2 = \"https://arxiv.org/pdf/2403.05530\" # Replace with the URL to your second PDF\n\n# Retrieve and upload both PDFs using the File API\ndoc_data_1 = io.BytesIO(httpx.get(doc_url_1).content)\ndoc_data_2 = io.BytesIO(httpx.get(doc_url_2).content)\n\nsample_pdf_1 = client.files.upload(\n  file=doc_data_1,\n  config=dict(mime_type='application/pdf')\n)\nsample_pdf_2 = client.files.upload(\n  file=doc_data_2,\n  config=dict(mime_type='application/pdf')\n)\n\nprompt = \"What is the difference between each of the main benchmarks between these two papers? Output these in a table.\"\n\nresponse = client.models.generate_content(\n  model=\"gemini-1.5-flash\",\n  contents=[sample_pdf_1, sample_pdf_2, prompt])\nprint(response.text)",
    "from google import genai\n\nclient = genai.Client()\n\nprint(\"My files:\")\nfor f in client.files.list():\n    print(\"  \", f.name)",
    "from google import genai\nimport pathlib\n\nclient = genai.Client()\n\nfpath = pathlib.Path('example.txt')\nfpath.write_text('hello')\n\nfile = client.files.upload('example.txt')\n\nclient.files.delete(file.name)",
    "from google import genai\nfrom google.genai import types\nimport io\nimport httpx\n\nclient = genai.Client()\n\nlong_context_pdf_path = \"https://www.nasa.gov/wp-content/uploads/static/history/alsj/a17/A17_FlightPlan.pdf\" # Replace with the actual URL of your large PDF\n\n# Retrieve and upload the PDF using the File API\ndoc_io = io.BytesIO(httpx.get(long_context_pdf_path).content)\n\ndocument = client.files.upload(\n  path=doc_io,\n  config=dict(mime_type='application/pdf')\n)\n\n# Specify the model name and system instruction for caching\nmodel_name = \"gemini-1.5-flash-002\" # Ensure this matches the model you intend to use\nsystem_instruction = \"You are an expert analyzing transcripts.\"\n\n# Create a cached content object\ncache = client.caches.create(\n    model=model_name,\n    config=types.CreateCachedContentConfig(\n      system_instruction=system_instruction,\n      contents=[document], # The document(s) and other content you wish to cache\n    )\n)\n\n# Display the cache details\nprint(f'{cache=}')\n\n# Generate content using the cached prompt and document\nresponse = client.models.generate_content(\n  model=model_name,\n  contents=\"Please summarize this transcript\",\n  config=types.GenerateContentConfig(\n    cached_content=cache.name\n  ))\n\n# (Optional) Print usage metadata for insights into the API call\nprint(f'{response.usage_metadata=}')\n\n# Print the generated text\nprint('\\n\\n', response.text)",
    "from google import genai\n\nclient = genai.Client()\nfor c in client.caches.list():\n  print(c)",
    "from google import genai\nfrom google.genai import types\nimport datetime\n\nclient = genai.Client()\n\nmodel_name = \"models/gemini-1.5-flash-002\" \n\ncache = client.caches.create(\n    model=model_name,\n    config=types.CreateCachedContentConfig(\n      contents=['hello']\n    )\n)\n\nclient.caches.update(\n  name = cache.name,\n  config=types.UpdateCachedContentConfig(\n    ttl=f'{datetime.timedelta(hours=2).total_seconds()}s'\n  )\n)",
    "from google import genai\nfrom google.genai import types\nimport datetime\n\nclient = genai.Client()\n\nmodel_name = \"models/gemini-1.5-flash-002\" \n\ncache = client.caches.create(\n    model=model_name,\n    config=types.CreateCachedContentConfig(\n      contents=['hello']\n    )\n)\n\nclient.caches.delete(name = cache.name)"
  ],
  "tables": []
}